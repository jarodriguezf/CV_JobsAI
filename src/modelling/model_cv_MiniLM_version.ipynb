{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jarod\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jarod\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cvs = pd.read_csv('../../data/raw_data/datasets/cv_raw_V0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eliminar caracter especial '\\n'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_line_break(df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.iloc[:, 1] = df_copy.iloc[:, 1].apply(lambda x: x.replace('\\n', ' '))\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cvs=delete_line_break(df_cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jarod\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo y tokenizador\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizamos los textos\n",
    "tokenized_inputs = tokenizer(df_cvs['cv'].to_list(), padding=True, \n",
    "                             truncation=True, max_length=768, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos el resultado en funcion de las representaciones de MiniLM\n",
    "outputs = model(tokenized_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturamos los embeddings\n",
    "embeddings = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza los vectores de embedding para asegurarte de que tengan longitud unitaria\n",
    "normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine(mean_embedding_1,mean_embedding_2):\n",
    "    similarity_score = cosine_similarity([mean_embedding_1], [mean_embedding_2])[0, 0]\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similitud_cv(cv_1, cv_2):\n",
    "    \n",
    "    # Calcular la media de los embeddings\n",
    "    mean_embedding_1 = np.mean(normalized_embeddings[cv_1], axis=0)\n",
    "    mean_embedding_2 = np.mean(normalized_embeddings[cv_2], axis=0)\n",
    "\n",
    "    # Calcular la similitud coseno entre los embeddings\n",
    "    similarity_score = calculate_cosine(mean_embedding_1,mean_embedding_2)\n",
    "\n",
    "    # Mostrar en pantalla resultados\n",
    "    print(f\"La similaridad entre el CV {cv_1} y {cv_2} es de:\", similarity_score)\n",
    "    print('\\n------------')\n",
    "    print(f'CV con id {cv_1}')\n",
    "    print(df_cvs['cv'][cv_1])\n",
    "    print('\\n------------')\n",
    "    print(f'CV con id {cv_2}')\n",
    "    print(df_cvs['cv'][cv_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similaridad entre el CV 10 y 23 es de: 0.24017674\n",
      "\n",
      "------------\n",
      "CV con id 10\n",
      "Enfoque en la experiencia en Cisco  Nombre: Juan Pérez  Resumen: Ingeniero de Redes con más de 5 años de experiencia en diseño, implementación y mantenimiento de redes Cisco. Especializado en enrutamiento y conmutación, seguridad de red y administración de dispositivos Cisco.  Experiencia Laboral:  Ingeniero de Redes en ABC Solutions (2018 - Presente) Lideró el diseño e implementación de una red empresarial basada en Cisco para una empresa de manufactura. Realizó la configuración de dispositivos Cisco ISR, switches Catalyst y firewalls ASA. Técnico de Redes en XYZ Networking (2015 - 2018) Proporcionó soporte técnico y mantenimiento preventivo a la infraestructura de red de clientes, incluida la resolución de problemas y actualizaciones de firmware. Educación:  Licenciatura en Ingeniería de Telecomunicaciones, Universidad Nacional (2014) Certificaciones:  Cisco Certified Network Professional (CCNP) Cisco Certified Network Associate (CCNA) Cisco Certified Design Associate (CCDA) Habilidades Técnicas:  Routing y Switching: OSPF, EIGRP, VLANs, STP Seguridad de Red: Firewalls Cisco ASA, VPN Herramientas: Cisco Packet Tracer, Wireshark   \n",
      "\n",
      "------------\n",
      "CV con id 23\n",
      "Aspirante a Analista de Datos  Nombre: Alejandro Martínez  Resumen Profesional: Graduado recientemente en Estadística con un fuerte interés en el análisis de datos y la visualización de datos. Conocimientos en herramientas estadísticas como R y Python, así como en técnicas de visualización de datos utilizando ggplot2 y Matplotlib. En busca de oportunidades para aplicar habilidades analíticas en entornos empresariales y adquirir experiencia práctica en el campo del análisis de datos.  Educación:  Licenciatura en Estadística, Universidad Politécnica Proyectos Destacados:  Análisis exploratorio de datos utilizando R y ggplot2 para visualizar patrones y tendencias en un conjunto de datos de accidentes de tráfico. Desarrollo de un panel interactivo de visualización de datos utilizando Python y Matplotlib para representar datos económicos. Aptitudes:  Análisis de Datos Visualización de Datos R y Python\n"
     ]
    }
   ],
   "source": [
    "similitud_cv(10, 23)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
